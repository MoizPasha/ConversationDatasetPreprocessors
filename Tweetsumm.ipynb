{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8841,"sourceType":"datasetVersion","datasetId":4133},{"sourceId":12352322,"sourceType":"datasetVersion","datasetId":7787475}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#TweetSum Processor from Github https://github.com/guyfe/Tweetsumm\nfrom typing import List\nimport csv\nimport json\nimport argparse\n\n\nclass Turn():\n    def __init__(self, is_agent : bool, sentences : List[str]):\n        self._is_agent = is_agent\n        self.sentences = sentences\n\n    def is_agent(self):\n        return self._is_agent\n\n    def get_sentences(self):\n        return self.sentences\n\n    def get_json(self) -> json:\n        result = {\n            'is_agent' : self.is_agent(),\n            'sentences' : self.sentences\n        }\n        return json.dumps(result)\n\n    def __str__(self):\n        return ('Agent:\\t' if self.is_agent() else 'Customer:\\t')  + ' '.join(self.sentences)\n\n\nclass Dialog():\n    def __init__(self, dialog_id: str, turns: List[Turn]):\n        self.dialog_id = dialog_id\n        self.turns = turns\n\n    def get_dialog_id(self) -> str:\n        return self.dialog_id\n\n    def get_turns(self) -> List[Turn]:\n        return self.turns\n\n    def get_json(self) -> json:\n        turn_list = [json.loads(turn.get_json()) for turn in self.turns]\n        result = {\n            'dialog_id' : self.dialog_id,\n            'turns' : turn_list\n        }\n        return json.dumps(result)\n\n    def __str__(self):\n        result = self.dialog_id + '\\n'\n        for turn in self.turns :\n            result += '\\t' + str(turn) + '\\n'\n        return result\n\n\nclass DialogWithSummaries():\n    def __init__(self, dialog_id: str, turns: List[Turn],\n                 extractive_summaries: List[List[Turn]],\n                 abstractive_summaries: List[List[str]]):\n        self.dialog = Dialog(dialog_id, turns)\n        self.extractive_summaries = extractive_summaries\n        self.abstractive_summaries = abstractive_summaries\n\n    def get_dialog(self) -> Dialog:\n        return self.dialog\n\n    def get_extractive_summaries(self) -> List[List[Turn]]:\n        return self.extractive_summaries\n\n    def get_abstractive_summaries(self) -> List[List[str]]:\n        return self.abstractive_summaries\n\n    def get_json(self) -> json:\n        dialog = json.loads(self.dialog.get_json())\n        extractive_summaries_to_json = list()\n        for summ in self.extractive_summaries:\n            summ_json = [json.loads(turn.get_json()) for turn in summ]\n            extractive_summaries_to_json.append(summ_json)\n        abstractive_summaries_to_json = list()\n        for summ in self.abstractive_summaries:\n            abst_json = [txt for txt in summ ]\n            abstractive_summaries_to_json.append(abst_json)\n\n        result = {\n            'dialog' : dialog,\n            'summaries' : {\n                'extractive_summaries' : extractive_summaries_to_json,\n                'abstractive_summaries' : abstractive_summaries_to_json\n\n            }\n        }\n\n        return json.dumps(result)\n\n    def __str__(self):\n        result = str(self.dialog)\n        result += '\\n'\n        # Extractive summaries:\n        result += 'Extractive summaries:\\n'\n        result += '=-=-=-=-=-=-=-=-=-=-=\\n'\n        for cnt,extractive_summary in enumerate(self.extractive_summaries):\n            result += ('{0}:\\n'.format(cnt))\n            for turn in extractive_summary:\n                result += '\\t' + str(turn) +'\\n'\n            result += '\\n'\n\n        # Abstractive summaries:\n        result += 'Abstractive summaries:\\n'\n        result += '=-=-=-=-=-=-=-=-=-=-=\\n'\n        for cnt,abstractive_summary in enumerate(self.abstractive_summaries):\n            result += ('{0}:\\n'.format(cnt))\n            result += '\\t' + ' '.join(abstractive_summary) +'\\n'\n            result += '\\n'\n        return result\n\n\nclass TweetSumProcessor():\n    def __init__(self, path_to_twitter_kaggle_file):\n        self.tweet_id_to_content = dict()\n        with open(path_to_twitter_kaggle_file) as f:\n            csv_reader = csv.reader(f)\n            # We skip header\n            next(csv_reader)\n            for line in csv_reader:\n                tweet_id = str(line[0])\n                in_bound = line[2]\n                text = line[4]\n                self.tweet_id_to_content[tweet_id] = (in_bound, text)\n\n    def __get_turn(self, tweet_id : str, sentence_offsets : List[dict]) -> Turn:\n        content = self.tweet_id_to_content[str(tweet_id)]\n        in_bound = content[0]\n        text = content[1]\n        sentences = list()\n        for offset in sentence_offsets:\n            start, end = offset.replace('[', '').replace(']', '').split(',')\n            sentence = text[int(start):int(end)]\n            sentences.append(sentence)\n        turn = Turn(is_agent=('FALSE' == str(in_bound).upper()), sentences=sentences)\n\n        return turn\n\n    def __get_turns(self, tweet_ids_sentence_offsets: List[dict]) -> List[Turn]:\n        turns = list()\n        for tweet_id_sentence_offset in tweet_ids_sentence_offsets :\n            tweet_id = tweet_id_sentence_offset['tweet_id']\n            offsets = tweet_id_sentence_offset['sentence_offsets']\n\n            turns.append(self.__get_turn(tweet_id, offsets))\n\n        return turns\n\n    def __get_extractive_summaries(self, annotations) -> List[List[Turn]]:\n        extractive_summaries = list()\n        for annotation in annotations:\n            if 'extractive' in annotation.keys():\n                extractive_summary = list()\n                extractive_annotation = annotation['extractive']\n                if extractive_annotation :\n                    for sentence in extractive_annotation :\n                        tweet_id = sentence['tweet_id']\n                        offset = sentence['sentence_offset']\n                        turn = self.__get_turn(tweet_id, [offset])\n                        extractive_summary.append(turn)\n                    extractive_summaries.append(extractive_summary)\n\n        return extractive_summaries\n\n    @staticmethod\n    def __get_abstractive_summaries(annotations) -> List[List[str]]:\n        summaries = list()\n        for annotation in annotations:\n            if 'abstractive' in annotation.keys():\n                abstractive_summary = annotation['abstractive']\n                summaries.append(abstractive_summary)\n        return summaries\n\n    def get_dialog_with_summaries(self, tweet_sum_lines: List[str]) -> List[DialogWithSummaries]:\n        result = list()\n\n        for tweet_sum_line in tweet_sum_lines:\n            tweet_sum_dict = json.loads(tweet_sum_line)\n            conversation_id = tweet_sum_dict['conversation_id']\n            tweet_ids_sentence_offsets = tweet_sum_dict['tweet_ids_sentence_offset']\n            annotations = tweet_sum_dict['annotations']\n\n            turns = self.__get_turns(tweet_ids_sentence_offsets)\n            extractive_summaries = self.__get_extractive_summaries(annotations)\n            abstractive_summaries = self.__get_abstractive_summaries(annotations)\n\n            dialog_with_summaries = DialogWithSummaries(dialog_id=conversation_id,\n                                                        turns=turns,\n                                                        extractive_summaries=extractive_summaries,\n                                                        abstractive_summaries=abstractive_summaries)\n            result.append(dialog_with_summaries)\n        return result\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T13:59:20.768982Z","iopub.execute_input":"2025-07-02T13:59:20.769287Z","iopub.status.idle":"2025-07-02T13:59:20.803278Z","shell.execute_reply.started":"2025-07-02T13:59:20.769266Z","shell.execute_reply":"2025-07-02T13:59:20.802147Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"processor = TweetSumProcessor('/kaggle/input/customer-support-on-twitter/twcs/twcs.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T14:09:00.162993Z","iopub.execute_input":"2025-07-02T14:09:00.163381Z","iopub.status.idle":"2025-07-02T14:09:14.480116Z","shell.execute_reply.started":"2025-07-02T14:09:00.163324Z","shell.execute_reply":"2025-07-02T14:09:14.479146Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import os\n\nfiles = []\nfor dirname, _, filenames in os.walk('/kaggle/input/tweetsum'):\n    for filename in filenames:\n        files.append(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T14:23:45.404655Z","iopub.execute_input":"2025-07-02T14:23:45.404964Z","iopub.status.idle":"2025-07-02T14:23:45.409656Z","shell.execute_reply.started":"2025-07-02T14:23:45.404944Z","shell.execute_reply":"2025-07-02T14:23:45.408948Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"conv_id = 30000 # Custom Start number\noutput_data = {}\n\nfor file in files:\n    with open(file) as f:\n        dialog_summaries = processor.get_dialog_with_summaries(f.readlines())\n        for dialog_summary in dialog_summaries:\n            messages = []\n            dialog = dialog_summary.get_dialog()\n            turns = dialog.get_turns()\n            if len(turns) >= 8:\n                mID = 1\n                for turn in turns:\n                    messages.append({\n                        'from': 'Agent' if turn.is_agent() else 'Customer',\n                        'message_id': mID,\n                        'message': ''.join(turn.get_sentences())\n                    })\n                    mID += 1\n                output_data[conv_id] = messages\n                conv_id += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T14:43:17.730796Z","iopub.execute_input":"2025-07-02T14:43:17.731080Z","iopub.status.idle":"2025-07-02T14:43:18.155214Z","shell.execute_reply.started":"2025-07-02T14:43:17.731062Z","shell.execute_reply":"2025-07-02T14:43:18.154169Z"},"_kg_hide-output":false},"outputs":[],"execution_count":84},{"cell_type":"code","source":"# Save to JSON file\n#with open('Tweetsumm_AbdulMoizPasha.json', 'w') as out_file:\n#    json.dump(output_data, out_file, indent=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}